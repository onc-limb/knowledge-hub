学習させたAIモデルの解答精度が悪くなってきた時に、再学習を行う。
基本的にはモデルを一から学習させる。
すでに学習しているモデルに追加で学習させることをファインチューニングと呼ぶ。しかし、ファインチューニングは過去の知識を忘れる危険性があるため運用は注意

全く同じデータを使用して一から学習させたとしても、学習フローの中にランダム性が存在しているため、全く同じモデルが生まれるわけではない。